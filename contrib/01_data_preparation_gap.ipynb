{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Introduction by Stefan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition\n",
    "We downloaded curated sequences for CD-box and HACA-box RNAs from variuos species from the SNOPY database (http://snoopy.med.miyazaki-u.ac.jp/).\n",
    "You can find the sequences in the \"SNOPY_CDBOX_curated.fasta\" and the \"SNOPY_HACABOX_curated.fasta\" files, a common data format for DNA/RNA/Protein sequence data.\n",
    "If working in JupyterLab you can easily inspect the .fasta files with the text editor by double-clicking the file in the \"File Browser\" pane on the left.\n",
    "What do you notice? How could this be relevant later on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleansing\n",
    "Some species may have multiple copies of these RNAs and/or closely related species might have highly similar sequences. Having multiple highly similar or identical copies of a sequence can impede our models from learning a good generalization.\n",
    "#### CD-HIT (http://weizhongli-lab.org/cd-hit/)\n",
    "We will use cd-hit-est to cluster highly similar sequences and create sets of representative sequences for both classes. <br>\n",
    "Verify cd-hit-est is installed and find out more about it by running \"cd-hit-est -h\". <br> You can run shell commands directly from jupyter code cells by prefixing the command with a \"!\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd-hit-est -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CD-HIT parameters\n",
    "Below are the parameters for our clustering runs. Run the cell please."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_identity = 0.9 # (-c)\n",
    "word_size = 8 # recommended for 0.9 identity (-n)\n",
    "threads = 0 # use all available CPUs (-T)\n",
    "desc_len = 0 # keep description up until first white space (-d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster CD-box sequences\n",
    "Start by clustering the CD-box sequences. <br>\n",
    "You can use variables in shell commands by enclosing them in curly braces i.e like this {variable}. <br>\n",
    "You could define variables for the input file (-i) and output file (-o) parameters as well. <br>\n",
    "Now run cd-hit-est using all of the defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_fasta_in = \"SNOPY_CDBOX_curated.fasta\" # (-i)\n",
    "cd_clustered = \"SNOPY_CDBOX_clustered.fasta\" # (-o)\n",
    "\n",
    "!cd-hit-est -i {} -o {} -c {} -n {} -T {} -d {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster HACA-box sequences\n",
    "Repeat the steps for the HACA-box sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haca_fasta_in = \"SNOPY_HACABOX_curated.fasta\"\n",
    "haca_clustered = \"SNOPY_HACABOX_clustered.fasta\"\n",
    "\n",
    "!cd-hit-est -i {} -o {} -c {} -n {} -T {} -d {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the sequences\n",
    "We are now ready to read in the two sets of representative sequences. <br>\n",
    "The output of cd-hit-est are .fasta files again. We can use the \"parse\" function from the SeqIO module from Biopython (https://biopython.org/wiki/SeqIO) to read sequences and identifiers from the fasta file.\n",
    "(Since we are only dealing with two files following exactly the same format you could also easily roll your own fasta reader.) <br>\n",
    "The pandas library is a powerful friend when handling data (https://pandas-docs.github.io/pandas-docs-travis/index.html).<br>\n",
    "Create two pandas DataFrames (for each class) with the identifier as index and one column named \"Seq\" for the sequence. <br>\n",
    "(You could f.e. put all sequences into a dictionary, which can then be read into a pandas DataFrame)<br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in seqs into two dicts\n",
    "from Bio import SeqIO # to read fasta\n",
    "\n",
    "dict_cd = {record.id: str().upper() for record in SeqIO.parse()}\n",
    "dict_haca = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two DataFrames from the dicts\n",
    "import pandas as pd\n",
    "\n",
    "df_cd = pd.DataFrame.from_dict(dict_cd, orient=\"index\", columns=[\"Seq\"])\n",
    "df_haca = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column \"Label\" to both DataFrames containing the respective class label \"CD-box\" or \"HACA-box\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cd[\"Label\"] = \"CD-box\"\n",
    "df_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_haca[\"Label\"] = \"HACA-box\"\n",
    "df_haca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine both DataFrames to create our complete data set. (Save the resulting DataFrame to a csv file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = \n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some features to generate a first impression of our data. <br>\n",
    "Add a column \"Length\" containing the length of the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"Length\"] = df_all.Seq.map(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two commonly used features for DNA sequences are the \"GC content\" and the \"ATGC ratio\".<br>\n",
    "The GC content is the percentage of \"G\"s or \"C\"s in the whole sequence. <br>\n",
    "The ATGC ratio is the ratio of \"A\"s and \"T\"s to \"G\"s and \"C\"s. <br>\n",
    "Create two columns \"GC_content\" and \"ATGC_ratio\" containing the respective feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"GC_content\"] = df_all.Seq.map()\n",
    "df_all[\"ATGC_ratio\"] = df_all.Seq.map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a first overview of the data using the DataFrame's describe() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also interested in the differences between our classes.<br>\n",
    "<b>Generate a class-wise description using groupby() and describe()<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a visual impression of the distribution of the features in our data we can use the pairplot() function form the seaborn visualization library (https://seaborn.pydata.org/) <br>\n",
    "Generate a pair plot for the DataFrame. What is easily visible using the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # Seaborn visualization library (for pairs plot)\n",
    "sns.pairplot(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we are also interested in the differences between the two classes.<br>\n",
    "<b>Generate a pair plot colored by class (Label) (https://seaborn.pydata.org/generated/seaborn.pairplot.html)<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_all, hue = 'Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the DataFrame to a csv in case we need it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(\"df_ALL.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already noticed above (using describe) that we have a few more CD-box sequences than HACA-box sequences. <br>\n",
    "To balance our dataset we can use the \"resample\" function from scikit-learn (https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html).<br>\n",
    "<b>Downsample the larger class to the size of the smaller class and create a new balanced DataFrame.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "rnd_seed=42\n",
    "\n",
    "# We are going to remove the randomly selected sequences\n",
    "df_cd_ds = resample() # sample without replacement\n",
    "                      # class size difference\n",
    "                      # fix seed for reproducible results\n",
    "\n",
    "df_balanced =  # drop the selected sequences\n",
    "df_balanced.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling procedure should leave us with a representative sample, but let us check that we didn't end up with a skewed sample anyways.<br>\n",
    "<b>Use groupby(), describe() and element-wise substraction to analyse the differences between the balanced and the original data.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_balanced.groupby(\"Label\").describe() - df_all.groupby(\"Label\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(\"display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the balanced DataFrame to a csv in case we need it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.to_csv(\"df_balanced.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first simple classifier\n",
    "We already noticed using the pair plot that the sequence length distributions of the two classes seem to be quite different. Can we train a simple classifier with only the features we already constructed? The performance of this classifier can then be used to establish a baseline for our upcoming more complex models (i.e CNNs).<br>\n",
    "Wait! First things first. We need to split the data into a set used for training and a set used for testing.<br>\n",
    "<b>Use sklearn's train_test_split to create sets of training and test data and corresponding sets of labels. Use an 80/20 split.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "rnd_seed=42\n",
    "\n",
    "xTrain, xTest, yTrain, yTest ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yTrain.value_counts())\n",
    "print(yTest.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to train a \"Naive Bayes\" classifier using our features (https://scikit-learn.org/stable/modules/naive_bayes.html) <br>\n",
    "<b>Fit a GaussianNB classifier to the training dataset and generate predictions for the test dataset. Does it make sense to include all of the features?<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB() # create classifier\n",
    "gnb.fit() # train using only length and GC\n",
    "yPred = gnb.predict() # generate predictions\n",
    "\n",
    "yPred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the quality of our prediction scikit-learn provides us with many different metrics. (https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)<br>\n",
    "<b>Use sklearn.metrics to print out the accuracy_score and the matthews_corrcoef for the generated predictions.</b> (Are these good choices for our problem?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(yTest, yPred))\n",
    "print(\"MCC:\", metrics.matthews_corrcoef(yTest, yPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn also provides a classification report which includes commonly used metrics (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report)<br>\n",
    "<b>Print out the classification report for the predictions<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yTest, yPred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common way of looking at the confusion of a classifier is the confusion matrix.<br>\n",
    "<b>Use scikit-learn to create a confusion matrix for the predictions and print it</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat = confusion_matrix(yTest, yPred)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that pretty, is it? We can use the seaborn.heatmap and matplotlib to create a matrix that is a bit more appealing to the eye.<br>\n",
    "<b>Adjust the code below to generate a pretty confusion matrix<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "classes = [\"CD-box\", \"HACA-box\"]\n",
    "df_confmat = pd.DataFrame(conf_mat, columns=df_balanced.Label.unique(), index=df_balanced.Label.unique())\n",
    "\n",
    "ax= plt.subplot()\n",
    "\n",
    "sns.heatmap(df_confmat, annot=True, ax=ax, cmap=\"Blues\"); #annot=True to annotate cells\n",
    "\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels') \n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have established a (maybe crude) baseline for our classification problem let's create a simple CNN and find out if this will improve our scores in the next notebook \"02_first_CNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
